from IPython.display import HTML, display
import tabulate

import newspaper
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

import pandas as pd
import collections
from pprint import pprint

# Test domains
cnn = "https://edition.cnn.com/"
new_york_times = "https://www.nytimes.com/"

# Parameters
article_num = 10 # Number of articles to extract.
cluster_num = 5

# Build source. 
paper = newspaper.build(new_york_times, memoize_articles=False)

# Extract titles.
titles = []
for article in paper.articles[:article_num]:
    article.download()
    article.parse()
    titles.append(article.title)
    
pprint("--- Extracted titles ---")
print(pd.DataFrame(titles))
#display(HTML(tabulate.tabulate(titles, tablefmt='html')))


# Vectorizing with TF-IDF.
vectorizer = TfidfVectorizer()
tfidf_model = vectorizer.fit_transform(titles)

pprint("--- tfidf model ---")
pprint(pd.DataFrame(vectorizer.get_feature_names()))
print(tfidf_model)

# K-means Clustering.
km_model = KMeans(n_clusters=cluster_num)
km_model.fit(tfidf_model)

# Cluster output mapping.
clustering = collections.defaultdict(list)
for idx, label in enumerate(km_model.labels_):
    clustering[label].append(idx)

pprint("--- KMeans Clustering ---")
pprint(clustering)

# Sentence label mapping.
title_label_mapping = []
for label in clustering:
    for i in clustering[label]:
        title_label_mapping.append([label, titles[i]])

pprint("--- Title & Label Mapping ---")
display(HTML(tabulate.tabulate(title_label_mapping, tablefmt='html')))

# Set data for bar graph.
bar_graph = []
for i in clustering:
    label_num = len(clustering[i])
    bar_graph.append([i, label_num])

# Set graph x, y size.
x = range(0, len(bar_graph))
y = range(0, 30)

# Set y axis data and label.
y_data = [i[1] for i in bar_graph]
labels = [i[0] for i in bar_graph]

# Show graph
plt.bar(x, y_data, tick_label=labels, align="edge", linewidth=50)
plt.show()
